#!/usr/bin/env groovy

def RunPowershellCommand(psCmd) {
    bat "powershell.exe -NonInteractive -ExecutionPolicy Bypass -Command \"[Console]::OutputEncoding=[System.Text.Encoding]::UTF8;$psCmd;EXIT \$global:LastExitCode\""
}

def getTests(priority, platform) {
    def AZURE_VALIDATION_TESTS_HASH=[:]
    def HYPERV_VALIDATION_TESTS_HASH=[:]

    AZURE_VALIDATION_TESTS_HASH_P0 = [AZURE_P0_VALIDATION:"-TestPriority 0 -ExcludeTests 'NVIDIA-CUDA-DRIVER-VALIDATION,NVIDIA-GRID-DRIVER-VALIDATION,VERIFY-DPDK-COMPLIANCE'"]
    HYPERV_VALIDATION_TESTS_HASH_P0 = [HV_P0_VALIDATION:"-TestPriority 0 -ExcludeTests 'SRIOV-VERIFY-LSPCI,SRIOV-VERIFY-SINGLE-VF-CONNECTION,LIVE-MIGRATE'"]
    HYPERV_VALIDATION_SRIOV_TESTS_HASH_P0 = [HV_P0_SRIOV_VALIDATION:"-TestPriority 0 -TestCategory Functional -TestArea SRIOV"]

    AZURE_VALIDATION_TESTS_HASH_P1 = [AZURE_P1_FUNCTIONAL_VALIDATION:"-TestPriority 1 -TestCategory Functional -ExcludeTests 'NVIDIA-CUDA-DRIVER-VALIDATION-MAX-GPU,NVIDIA-GRID-DRIVER-VALIDATION-MAX-GPU,INFINIBAND-OPEN-MPI-2VM,VERIFY-DPDK-FAILSAFE-DURING-TRAFFIC,VERIFY-DPDK-RING-LATENCY'"]
    HYPERV_VALIDATION_TESTS_HASH_P1 = [HV_P1_FUNCTIONAL_VALIDATION:"-TestCategory Functional -TestPriority 1 -ExcludeTests 'LIVE-MIGRATE-FAILOVER,DYNAMIC-MEMORY-HIGH-PRIORITY,SRIOV-DISABLE-ENABLE-PCI,SRIOV-VERIFY-SINGLE-VF-CONNECTION-ONE-VCPU,SRIOV-VERIFY-SINGLE-VF-CONNECTION-MAX-VCPU,SRIOV-VERIFY-MAX-VF-CONNECTION,SRIOV-VERIFY-MAX-VF-CONNECTION-MAX-VCPU,SRIOV-ADD-MAX-NICS-DURING-PROVISION,SRIOV-INTERRUPTS-CHANGE,SRIOV-DISABLEVF-ON-GUEST,SRIOV-RELOAD-MODULE,SRIOV-DISABLEVF-PING,SRIOV-DISABLEVF-IPERF,SRIOV-DETACH-NIC,SRIOV-DISABLEVF-ONHOST,SRIOV-DISABLE-NIC,SRIOV-DISABLE-VMQ,SRIOV-CHANGE-RSS,SRIOV-MEASURE-VF-FAILBACK,SRIOV-MULTICAST,SRIOV-BROADCAST,SRIOV-REBOOT-VM,SRIOV-STRESS-SAVE,SRIOV-STRESS-PAUSE'",
        HV_P1_STRESS_VALIDATION:"-TestPriority 1 -TestCategory Stress"]
    HYPERV_VALIDATION_SRIOV_TESTS_HASH_P1 = [HV_P1_SRIOV_VALIDATION:"-TestPriority 1 -TestCategory Functional -TestArea SRIOV"]

    AZURE_VALIDATION_TESTS_HASH_P2 = [AZURE_P2_FUNCTIONAL_VALIDATION:"-TestPriority 2 -TestCategory Functional",
        AZURE_P2_COMMUNITY_VALIDATION:"-TestPriority 2 -TestCategory Community",
        AZURE_P2_STRESS_VALIDATION:"-TestPriority 2 -TestCategory Stress"]
    HYPERV_VALIDATION_TESTS_HASH_P2= [HV_P2_FUNCTIONAL_VALIDATION:"-TestCategory Functional -TestPriority 2 -ExcludeTests 'SRIOV-IPERF-STRESS,SRIOV-MOVE-VHD'",
        HV_P2_STRESS_VALIDATION:"-TestPriority 2 -TestCategory Stress",
        HV_P2_COMMUNITY_VALIDATION:"-TestPriority 2 -TestCategory Community"]
    HYPERV_VALIDATION_SRIOV_TESTS_HASH_P2 = [HV_P2_SRIOV_VALIDATION:"-TestPriority 2 -TestCategory Functional -TestArea SRIOV"]

    AZURE_VALIDATION_TESTS_HASH_P3 = [AZURE_P3_COMMUNITY_VALIDATION:"-TestPriority 2 -TestCategory Community"]
    HYPERV_VALIDATION_TESTS_HASH_P3= [HV_P3_VALIDATION:"-TestPriority 3"]

    if ("${priority}" == "P0") {
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P0
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P0
    }
    if ("${priority}" == "P1") {
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P0
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P0
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P1
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P1
    }
    if ("${priority}" == "P2") {
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P0
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P0
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P1
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P1
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P2
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P2
    }
    if ("${priority}" == "P3") {
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P0
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P0
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P1
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P1
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P2
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P2
        AZURE_VALIDATION_TESTS_HASH += AZURE_VALIDATION_TESTS_HASH_P3
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_TESTS_HASH_P3
    }
    if ("${priority}" == "P0-SRIOV") {
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_SRIOV_TESTS_HASH_P0
    }
    if ("${priority}" == "P1-SRIOV") {
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_SRIOV_TESTS_HASH_P0
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_SRIOV_TESTS_HASH_P1
    }
    if ("${priority}" == "P2-SRIOV") {
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_SRIOV_TESTS_HASH_P0
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_SRIOV_TESTS_HASH_P1
        HYPERV_VALIDATION_TESTS_HASH += HYPERV_VALIDATION_SRIOV_TESTS_HASH_P2
    }
    if ("${platform}".contains("Azure")) {
        return AZURE_VALIDATION_TESTS_HASH
    }
    if ("${platform}".contains("HyperV")) {
        return HYPERV_VALIDATION_TESTS_HASH
    }
}
def GetTestResults(type) {
    withEnv(["Type=${type}"]) {
        def returnValues = powershell returnStdout: true, script: '''$file = Get-Item ".\\Report\\*-junit.xml" | Sort-Object LastWriteTimeUtc | select -Last 1
           $content = [xml](Get-Content $file)
           $failCase = [int]($content.testsuites.testsuite.failures)
           $allCase = [int]($content.testsuites.testsuite.tests)
           $abortCase = [int]($content.testsuites.testsuite.errors)
           $skippedCase = [int]($content.testsuites.testsuite.skipped)
           $passCase = $allCase - $failCase - $abortCase - $skippedCase

           if ($env:Type -eq "pass") {
               return $passCase
           } elseif ($env:Type -eq "abort") {
               return $abortCase
           } elseif ($env:Type -eq "fail") {
               return $failCase
           } elseif ($env:Type -eq "skipped") {
               return $skippedCase
           } elseif ($env:Type -eq "all") {
               return $allCase
           }
           '''
        return "${returnValues}"
    }
}

def reportStageStatus(stageName, stageStatus) {
    script {
        env.STAGE_NAME_REPORT = stageName
        env.STAGE_STATUS_REPORT = stageStatus
    }
    withCredentials(bindings: [file(credentialsId: 'KERNEL_QUALITY_REPORTING_DB_CONFIG',
                                    variable: 'PERF_DB_CONFIG')]) {
        dir('kernel_version_report' + env.BUILD_NUMBER + env.BRANCH_NAME) {
              unstash 'kernel_version_ini'
              sh returnStatus: true, script: '''
                  #!/bin/bash
                  KERNEL_SOURCE="${KERNEL_GIT_URL##*/}"
                  KERNEL_SOURCE="${KERNEL_SOURCE%.*}"
                  KERNEL_SOURCE=$(echo $KERNEL_SOURCE | tr /a-z/ /A-Z/)
                  bash "${WORKSPACE}/scripts/reporting/report_stage_state.sh" \
                      --pipeline_name "pipeline-linux-upstream-validation/${BRANCH_NAME}" \
                      --pipeline_build_number "${BUILD_NUMBER}" \
                      --pipeline_stage_status "${STAGE_STATUS_REPORT}" \
                      --pipeline_stage_name "${STAGE_NAME_REPORT}" \
                      --kernel_info "./scripts/package_building/kernel_versions.ini" \
                      --kernel_source "${KERNEL_SOURCE}" --kernel_branch "${KERNEL_GIT_BRANCH}" \
                      --distro_version "${DISTRO_VERSION}" --db_config "${PERF_DB_CONFIG}" || true
              '''
        }
    }
}


def getVhdLocation(basePath, distroVersion) {
    def distroFamily = distroVersion.split('_')[0]
    return "${basePath}\\" + distroFamily + "\\" + distroVersion + "\\" + distroVersion + ".vhdx"
}

def prepareEnv(branch, remote, distroVersion) {
    cleanWs()
    git branch: branch, url: remote
    script {
      env.AZURE_OS_IMAGE = env.AZURE_UBUNTU_IMAGE_BIONIC
      env.PACKAGE_TYPE = "deb"
      if (distroVersion.toLowerCase().contains("centos")) {
        env.AZURE_OS_IMAGE = env.AZURE_CENTOS_7_IMAGE
        env.PACKAGE_TYPE = "rpm"
      }
    }
}

def unstashKernel(kernelStash) {
    unstash kernelStash
    powershell """
        \$rmPath = "\${env:ProgramFiles}\\Git\\usr\\bin\\rm.exe"
        \$basePath = "./scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${kernelStash}/*/${env.PACKAGE_TYPE}"

        & \$rmPath -rf "\${basePath}/*dbg*"
        & \$rmPath -rf "\${basePath}/*devel*"
        & \$rmPath -rf "\${basePath}/*debug*"
    """
}


pipeline {
  parameters {
    choice(choices: 'git://git.kernel.org/pub/scm/linux/kernel/git/next/linux-next.git\nhttps://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git\ngit://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git', description: 'Kernel tree repo (upstream, net-next, linux stable)', name: 'KERNEL_GIT_URL')
    string(defaultValue: "master", description: 'Branch to be built', name: 'KERNEL_GIT_BRANCH')
    choice(choices: 'Ubuntu_18.04.1\nCentOS_7.5', description: 'Distro version.', name: 'DISTRO_VERSION')
    choice(choices: 'Standard_E64_v3\nStandard_F72s_v2', description: 'Azure large boot flavor', name: 'LISAV2_AZURE_VM_SIZE_LARGE')
    choice(choices: 'False\nTrue', description: 'Enable kernel debug', name: 'KERNEL_DEBUG')
    choice(choices: 'P0\nP1\nP2\nP3\n', description: 'Priority', name: 'PRIORITY')
    string(defaultValue: "build_artifacts, publish_temp_artifacts, boot_test, publish_artifacts, validation, validation_hyperv, validation_hyperv_sriov, publish_azure_vhd, validation_azure, publish_results, send_mail",
           description: 'What stages to run', name: 'ENABLED_STAGES')
  }
  environment {
    LISAV2_REMOTE = "https://github.com/lis/LISAv2.git"
    LISAV2_BRANCH = "master"
    LISAV2_HYPERV_REGION = "hyper-v"
    LISAV2_AZURE_REGION = "eastus2"
    LISAV2_RG_IDENTIFIER = "upstreamk"
    KERNEL_ARTIFACTS_PATH = 'upstream-kernel-artifacts'
    UBUNTU_VERSION = '16'
    BUILD_PATH = '/mnt/tmp/upstream-kernel-build-folder'
    KERNEL_CONFIG = 'Microsoft/config-azure'
    CLEAN_ENV = 'True'
    USE_CCACHE = 'True'
    BUILD_NAME = 'u'
    CREATE_CHANGELOG = 'False'
    INSTALL_DEPS = 'True'
    USE_KERNEL_FOLDER_PREFIX = 'True'
    THREAD_NUMBER = 'x3'
    AZURE_UBUNTU_IMAGE_BIONIC = "Canonical UbuntuServer 18.04-DAILY-LTS latest"
    AZURE_CENTOS_7_IMAGE = "OpenLogic CentOS 7.5 latest"
    FUNC_FAIL_ONAZURE = 0
    FUNC_FAIL_ONLOCAL = 0
    FUNC_PASS_ONAZURE = 0
    FUNC_PASS_ONLOCAL = 0
    FUNC_ABORT_ONAZURE = 0
    FUNC_ABORT_ONLOCAL = 0
    FUNC_SKIP_ONAZURE = 0
    FUNC_SKIP_ONLOCAL = 0
  }
  options {
    overrideIndexTriggers(false)
  }
  agent {
    node {
      label 'meta_slave'
    }
  }
  stages {
          stage('build_artifacts_ubuntu') {
              when {
                beforeAgent true
                expression { params.DISTRO_VERSION.toLowerCase().contains('ubuntu') }
                expression { params.ENABLED_STAGES.contains('build_artifacts') }
              }
              agent {
                node {
                  label 'ubuntu_kernel_builder'
                }
              }
              steps {
              stash includes: 'scripts/package_building/kernel_versions.ini', name: 'kernel_version_ini'
              sh '''#!/bin/bash
                set -xe
                echo "Building artifacts..."
                pushd "$WORKSPACE/scripts/package_building"
                bash build_artifacts.sh \\
                    --git_url "${KERNEL_GIT_URL}" \\
                    --git_branch "${KERNEL_GIT_BRANCH}" \\
                    --destination_path "${BUILD_NUMBER}-${BRANCH_NAME}-${KERNEL_ARTIFACTS_PATH}" \\
                    --install_deps "${INSTALL_DEPS}" \\
                    --thread_number "${THREAD_NUMBER}" \\
                    --debian_os_version "${UBUNTU_VERSION}" \\
                    --build_path "${BUILD_PATH}" \\
                    --kernel_config "${KERNEL_CONFIG}" \\
                    --clean_env "${CLEAN_ENV}" \\
                    --use_ccache "${USE_CCACHE}" \\
                    --use_kernel_folder_prefix "${USE_KERNEL_FOLDER_PREFIX}" \\
                    --create_changelog "${CREATE_CHANGELOG}" \\
                    --enable_kernel_debug "${KERNEL_DEBUG}"
                popd
                '''
                sh '''#!/bin/bash
                  echo ${BUILD_NUMBER}-$(crudini --get scripts/package_building/kernel_versions.ini KERNEL_BUILT folder) > ./build_name
                '''
                script {
                  currentBuild.displayName = readFile "./build_name"
                }
                writeFile file: 'ARM_IMAGE_NAME.azure.env', text: 'Canonical UbuntuServer 16.04-LTS latest'
                writeFile file: 'ARM_OSVHD_NAME.azure.env', text: "SS-AUTOBUILT-Canonical-UbuntuServer-16.04-LTS-latest-${BUILD_NAME}${BUILD_NUMBER}.vhd"
                writeFile file: 'KERNEL_PACKAGE_NAME.azure.env', text: 'testKernel.deb'

                stash includes: '*.azure.env', name: 'azure.env'
                stash includes: 'scripts/package_building/kernel_versions.ini', name: 'kernel_version_ini'
                stash includes: ("scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${env.KERNEL_ARTIFACTS_PATH}/**/deb/**"),
                      name: "${env.KERNEL_ARTIFACTS_PATH}"
                sh '''
                    set -xe
                    rm -rf "scripts/package_building/${BUILD_NUMBER}-${BRANCH_NAME}-${KERNEL_ARTIFACTS_PATH}"
                '''
                archiveArtifacts 'scripts/package_building/kernel_versions.ini'
              }
              post {
                failure {
                  reportStageStatus("BuildSucceeded", 0)
                }
                success {
                  reportStageStatus("BuildSucceeded", 1)
                }
              }
          }
          stage('build_artifacts_centos') {
              when {
                beforeAgent true
                expression { params.DISTRO_VERSION.toLowerCase().contains('centos') }
                expression { params.ENABLED_STAGES.contains('build_artifacts') }
              }
              agent {
                node {
                  label 'centos_kernel_builder'
                }
              }
              steps {
                stash includes: 'scripts/package_building/kernel_versions.ini', name: 'kernel_version_ini'
                sh '''#!/bin/bash
                set -xe
                echo "Building artifacts..."
                pushd "$WORKSPACE/scripts/package_building"
                bash build_artifacts.sh \\
                    --git_url "${KERNEL_GIT_URL}" \\
                    --git_branch "${KERNEL_GIT_BRANCH}" \\
                    --destination_path "${BUILD_NUMBER}-${BRANCH_NAME}-${KERNEL_ARTIFACTS_PATH}" \\
                    --install_deps "${INSTALL_DEPS}" \\
                    --thread_number "${THREAD_NUMBER}" \\
                    --build_path "${BUILD_PATH}" \\
                    --kernel_config "${KERNEL_CONFIG}" \\
                    --clean_env "${CLEAN_ENV}" \\
                    --use_ccache "${USE_CCACHE}" \\
                    --use_kernel_folder_prefix "${USE_KERNEL_FOLDER_PREFIX}" \\
                popd
                '''
                sh '''#!/bin/bash
                  echo ${BUILD_NUMBER}-$(crudini --get scripts/package_building/kernel_versions.ini KERNEL_BUILT folder) > ./build_name
                '''
                script {
                  currentBuild.displayName = readFile "./build_name"
                }
                writeFile file: 'ARM_IMAGE_NAME.azure.env', text: 'OpenLogic CentOS 7.4 latest'
                writeFile file: 'ARM_OSVHD_NAME.azure.env', text: "SS-AUTOBUILT-OpenLogic-CentOS-7.4-latest-${BUILD_NAME}${BUILD_NUMBER}.vhd"
                writeFile file: 'KERNEL_PACKAGE_NAME.azure.env', text: 'testKernel.rpm'

                stash includes: '*.azure.env', name: 'azure.env'
                stash includes: 'scripts/package_building/kernel_versions.ini', name: 'kernel_version_ini'
                stash includes: ("scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${env.KERNEL_ARTIFACTS_PATH}/**/rpm/**"),
                      name: "${env.KERNEL_ARTIFACTS_PATH}"
                sh '''
                    set -xe
                    rm -rf "scripts/package_building/${BUILD_NUMBER}-${BRANCH_NAME}-${KERNEL_ARTIFACTS_PATH}"
                '''
                archiveArtifacts 'scripts/package_building/kernel_versions.ini'
              }
              post {
                failure {
                  reportStageStatus("BuildSucceeded", 0)
                }
                success {
                  reportStageStatus("BuildSucceeded", 1)
                }
              }
    }
    stage('publish_temp_artifacts') {
      when {
        beforeAgent true
        expression { params.ENABLED_STAGES.contains('publish_temp_artifacts') }
      }
      agent {
        node {
          label 'meta_slave'
        }
      }
      steps {
        dir("${env.KERNEL_ARTIFACTS_PATH}${env.BUILD_NUMBER}${env.BRANCH_NAME}") {
            unstash "${env.KERNEL_ARTIFACTS_PATH}"
            withCredentials([string(credentialsId: 'SMB_SHARE_URL', variable: 'SMB_SHARE_URL'),
                               usernamePassword(credentialsId: 'smb_share_user_pass',
                                                passwordVariable: 'PASSWORD',
                                                usernameVariable: 'USERNAME')]) {
                sh '''#!/bin/bash
                    set -xe
                    folder_prefix="${KERNEL_GIT_URL##*/}"
                    folder_prefix="${folder_prefix%.*}"
                    bash "${WORKSPACE}/scripts/utils/publish_artifacts_to_smb.sh" \\
                        --build_number "${BUILD_NUMBER}-${BRANCH_NAME}" \\
                        --smb_url "${SMB_SHARE_URL}/temp-kernel-artifacts" --smb_username "${USERNAME}" \\
                        --smb_password "${PASSWORD}" --artifacts_path "${KERNEL_ARTIFACTS_PATH}" \\
                        --artifacts_folder_prefix "${folder_prefix}"
                '''
            }
        }
      }
    }
    stage('boot_test') {
      when {
        beforeAgent true
        expression { params.ENABLED_STAGES.contains('boot_test') }
      }
      post {
        failure {
          reportStageStatus("BootOnAzure", 0)
        }
        success {
          reportStageStatus("BootOnAzure", 1)
        }
      }
      parallel {
        stage('boot_test_large') {
            when {
              beforeAgent true
              expression { params.ENABLED_STAGES.contains('boot_test_large') }
            }
            agent {
              node {
                label 'azure'
              }
            }
            steps {
                withCredentials(bindings: [
                  file(credentialsId: 'Azure_Secrets_TESTONLY_File',
                       variable: 'Azure_Secrets_File')
                ]) {
                    prepareEnv(LISAV2_BRANCH, LISAV2_REMOTE, DISTRO_VERSION)
                    unstashKernel(env.KERNEL_ARTIFACTS_PATH)
                    RunPowershellCommand(".\\Run-LisaV2.ps1" +
                        " -TestLocation '${LISAV2_AZURE_REGION}'" +
                        " -RGIdentifier '${LISAV2_RG_IDENTIFIER}'" +
                        " -TestPlatform 'Azure'" +
                        " -CustomKernel 'localfile:./scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${env.KERNEL_ARTIFACTS_PATH}/*/${env.PACKAGE_TYPE}/*.${env.PACKAGE_TYPE}'" +
                        " -OverrideVMSize '${LISAV2_AZURE_VM_SIZE_LARGE}'" +
                        " -ARMImageName '${AZURE_OS_IMAGE}'" +
                        " -TestNames 'VERIFY-LIS-MODULES-VERSION'" +
                        " -StorageAccount 'ExistingStorage_Standard'" +
                        " -XMLSecretFile '${Azure_Secrets_File}'" +
                        " -CustomParameters 'DiskType = Managed'"
                    )
                }
            }
            post {
              always {
                junit "Report\\*-junit.xml"
                archiveArtifacts "*-TestLogs.zip"
              }
            }
        }
        stage('boot_test_small') {
            agent {
              node {
                label 'azure'
              }
            }
            steps {
                withCredentials(bindings: [
                  file(credentialsId: 'Azure_Secrets_TESTONLY_File',
                       variable: 'Azure_Secrets_File')
                ]) {
                    prepareEnv(LISAV2_BRANCH, LISAV2_REMOTE, DISTRO_VERSION)
                    unstashKernel(env.KERNEL_ARTIFACTS_PATH)
                    RunPowershellCommand(".\\Run-LisaV2.ps1" +
                        " -TestLocation '${LISAV2_AZURE_REGION}'" +
                        " -RGIdentifier '${LISAV2_RG_IDENTIFIER}'" +
                        " -TestPlatform 'Azure'" +
                        " -CustomKernel 'localfile:./scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${env.KERNEL_ARTIFACTS_PATH}/*/${env.PACKAGE_TYPE}/*.${env.PACKAGE_TYPE}'" +
                        " -ARMImageName '${AZURE_OS_IMAGE}'" +
                        " -TestNames 'VERIFY-LIS-MODULES-VERSION'" +
                        " -StorageAccount 'ExistingStorage_Standard'" +
                        " -XMLSecretFile '${Azure_Secrets_File}'" +
                        " -CustomParameters 'DiskType = Managed'"
                    )
                }
            }
            post {
              always {
                junit "Report\\*-junit.xml"
                archiveArtifacts "*-TestLogs.zip"
              }
            }
          }
      }
    }
    stage('publish_artifacts') {
      when {
        beforeAgent true
        expression { params.ENABLED_STAGES.contains('publish_artifacts') }
      }
      agent {
        node {
          label 'meta_slave'
        }
      }
      steps {
        dir("${env.KERNEL_ARTIFACTS_PATH}${env.BUILD_NUMBER}${env.BRANCH_NAME}") {
            unstash "${env.KERNEL_ARTIFACTS_PATH}"
            withCredentials([string(credentialsId: 'SMB_SHARE_URL', variable: 'SMB_SHARE_URL'),
                               usernamePassword(credentialsId: 'smb_share_user_pass', passwordVariable: 'PASSWORD', usernameVariable: 'USERNAME')
                               ]) {
                sh '''#!/bin/bash
                    set -xe
                    folder_prefix="${KERNEL_GIT_URL##*/}"
                    folder_prefix="${folder_prefix%.*}"
                    bash "${WORKSPACE}/scripts/utils/publish_artifacts_to_smb.sh" \\
                        --build_number "${BUILD_NUMBER}-${BRANCH_NAME}" \\
                        --smb_url "${SMB_SHARE_URL}/${folder_prefix}" --smb_username "${USERNAME}" \\
                        --smb_password "${PASSWORD}" --artifacts_path "${KERNEL_ARTIFACTS_PATH}" \\
                        --artifacts_folder_prefix "${folder_prefix}"
                '''
            }
        }
      }
    }
    stage('publish_azure_vhd') {
      when {
        beforeAgent true
        expression { params.ENABLED_STAGES.contains('publish_azure_vhd') }
      }
      agent {
        node {
          label 'azure'
        }
      }
      steps {
        withCredentials(bindings: [
          file(credentialsId: 'Azure_Secrets_TESTONLY_File',
               variable: 'Azure_Secrets_File')
        ]) {
            prepareEnv(LISAV2_BRANCH, LISAV2_REMOTE, DISTRO_VERSION)
            unstashKernel(env.KERNEL_ARTIFACTS_PATH)
            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                " -TestLocation '${LISAV2_AZURE_REGION}'" +
                " -RGIdentifier '${LISAV2_RG_IDENTIFIER}'" +
                " -TestPlatform 'Azure'" +
                " -CustomKernel 'localfile:./scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${env.KERNEL_ARTIFACTS_PATH}/*/${env.PACKAGE_TYPE}/*.${env.PACKAGE_TYPE}'" +
                " -ARMImageName '${AZURE_OS_IMAGE}'" +
                " -TestNames 'CAPTURE-VHD-BEFORE-TEST'" +
                " -XMLSecretFile '${Azure_Secrets_File}'"
            )
            script {
                env.CapturedVHD = readFile 'CapturedVHD.azure.env'
            }
            stash includes: 'CapturedVHD.azure.env', name: 'CapturedVHD.azure.env'
            println("Captured VHD : ${env.CapturedVHD}")
        }
      }
      post {
        always {
          junit "Report\\*-junit.xml"
          archiveArtifacts "*-TestLogs.zip"
        }
      }
    }

    stage('validation') {
      parallel {
        stage('validation_azure') {
          when {
            beforeAgent true
            expression { params.ENABLED_STAGES.contains('validation_azure') }
          }
          agent {
            node {
              label 'azure'
            }
          }
          steps {
            withCredentials(bindings: [
              file(credentialsId: 'Azure_Secrets_TESTONLY_File',
                   variable: 'Azure_Secrets_File')
            ]) {
            script {
                prepareEnv(LISAV2_BRANCH, LISAV2_REMOTE, DISTRO_VERSION)
                hashtable=getTests("${PRIORITY}", "Azure")
                unstash 'CapturedVHD.azure.env'
                script {
                    env.CapturedVHD = readFile 'CapturedVHD.azure.env'
                }
                println("VHD under test : ${env.CapturedVHD}")
                def stepsForParallel = [:]
                hashtable.each {
                    def stepName = it.key
                    def test_cmd = it.value
                    stepsForParallel[stepName] = { ->
                        try {
                            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                            " -TestLocation '${LISAV2_AZURE_REGION}'" +
                            " -RGIdentifier '${LISAV2_RG_IDENTIFIER}'" +
                            " -TestPlatform 'Azure'" +
                            " ${test_cmd}" +
                            " -OsVHD '${CapturedVHD}'" +
                            " -XMLSecretFile '${Azure_Secrets_File}'" +
                            " -ExitWithZero")
                        } finally {
                            junit "Report\\*-junit.xml"
                            archiveArtifacts "*-TestLogs.zip"
                            script {
                                def passCount = GetTestResults("pass")
                                def abortCount = GetTestResults("abort")
                                def failCount = GetTestResults("fail")
                                def skippedCount = GetTestResults("skipped")
                                FUNC_PASS_ONAZURE = FUNC_PASS_ONAZURE.toInteger() + passCount.toInteger()
                                FUNC_ABORT_ONAZURE = FUNC_ABORT_ONAZURE.toInteger() + abortCount.toInteger()
                                FUNC_FAIL_ONAZURE = FUNC_FAIL_ONAZURE.toInteger() + failCount.toInteger()
                                FUNC_SKIP_ONAZURE = FUNC_SKIP_ONAZURE.toInteger() + skippedCount.toInteger()
                            }
                        }
                    }
                }
                parallel stepsForParallel
                }
            }
          }
        }

        stage('validation_hyperv') {
          when {
            beforeAgent true
            expression { params.ENABLED_STAGES.contains('validation_hyperv') }
          }
          agent {
            node {
              label 'hyper-v'
            }
          }
          steps {
            withCredentials(bindings: [
              file(credentialsId: 'HyperV_Secrets_File',
                   variable: 'HyperV_Secrets_File'),
              string(credentialsId: 'LISAV2_IMAGES_SHARE_URL',
                   variable: 'LISAV2_IMAGES_SHARE_URL')
            ]) {
            script {
                prepareEnv(LISAV2_BRANCH, LISAV2_REMOTE, DISTRO_VERSION)
                hashtable=getTests("${PRIORITY}", "HyperV")
                unstashKernel(env.KERNEL_ARTIFACTS_PATH)
                script {
                  env.HYPERV_VHD_PATH = getVhdLocation(LISAV2_IMAGES_SHARE_URL, DISTRO_VERSION)
                }
                println("Current VHD: ${env.HYPERV_VHD_PATH}")
                def stepsForParallel = [:]
                hashtable.each {
                    def stepName = it.key
                    def test_cmd = it.value
                    stepsForParallel[stepName] = { ->
                        try {
                            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                            " -TestLocation 'localhost'" +
                            " -RGIdentifier '${LISAV2_RG_IDENTIFIER}'" +
                            " -TestPlatform 'HyperV'" +
                            " ${test_cmd}" +
                            " -CustomKernel 'localfile:./scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${env.KERNEL_ARTIFACTS_PATH}/*/${env.PACKAGE_TYPE}/*.${env.PACKAGE_TYPE}'" +
                            " -OsVHD '${HYPERV_VHD_PATH}'" +
                            " -XMLSecretFile '${HyperV_Secrets_File}'" +
                            " -ExitWithZero")
                        } finally {
                            junit "Report\\*-junit.xml"
                            archiveArtifacts "*-TestLogs.zip"
                            script {
                                def passCount = GetTestResults("pass")
                                def abortCount = GetTestResults("abort")
                                def failCount = GetTestResults("fail")
                                def skippedCount = GetTestResults("skipped")
                                FUNC_PASS_ONLOCAL = FUNC_PASS_ONLOCAL.toInteger() + passCount.toInteger()
                                FUNC_ABORT_ONLOCAL = FUNC_ABORT_ONLOCAL.toInteger() + abortCount.toInteger()
                                FUNC_FAIL_ONLOCAL = FUNC_FAIL_ONLOCAL.toInteger() + failCount.toInteger()
                                FUNC_SKIP_ONLOCAL = FUNC_SKIP_ONLOCAL.toInteger() + skippedCount.toInteger()
                            }
                        }
                    }
                }
                parallel stepsForParallel
                }
            }
          }
        }

        stage('validation_hyperv_sriov') {
          when {
            beforeAgent true
            expression { params.ENABLED_STAGES.contains('validation_hyperv_sriov') }
          }
          agent {
            node {
              label 'sriov_mlnx'
            }
          }
          steps {
            withCredentials(bindings: [
              file(credentialsId: 'HyperV_Secrets_File',
                   variable: 'HyperV_Secrets_File'),
              string(credentialsId: 'LISAV2_IMAGES_SHARE_URL',
                   variable: 'LISAV2_IMAGES_SHARE_URL')
            ]) {
            script {
                prepareEnv(LISAV2_BRANCH, LISAV2_REMOTE, DISTRO_VERSION)
                hashtable=getTests("${PRIORITY}-SRIOV", "HyperV")
                unstashKernel(env.KERNEL_ARTIFACTS_PATH)
                script {
                  env.HYPERV_VHD_PATH = getVhdLocation(LISAV2_IMAGES_SHARE_URL, DISTRO_VERSION)
                }
                println("Current VHD: ${env.HYPERV_VHD_PATH}")
                def stepsForParallel = [:]
                hashtable.each {
                    def stepName = it.key
                    def test_cmd = it.value
                    stepsForParallel[stepName] = { ->
                        try {
                            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                            " -TestLocation 'localhost'" +
                            " -RGIdentifier '${LISAV2_RG_IDENTIFIER}'" +
                            " -TestPlatform 'HyperV'" +
                            " ${test_cmd}" +
                            " -CustomKernel 'localfile:./scripts/package_building/${env.BUILD_NUMBER}-${env.BRANCH_NAME}-${env.KERNEL_ARTIFACTS_PATH}/*/${env.PACKAGE_TYPE}/*.${env.PACKAGE_TYPE}'" +
                            " -OsVHD '${HYPERV_VHD_PATH}'" +
                            " -XMLSecretFile '${HyperV_Secrets_File}'" +
                            " -ExitWithZero")
                        } finally {
                            junit "Report\\*-junit.xml"
                            archiveArtifacts "*-TestLogs.zip"
                            script {
                                def passCount = GetTestResults("pass")
                                def abortCount = GetTestResults("abort")
                                def failCount = GetTestResults("fail")
                                def skippedCount = GetTestResults("skipped")
                                FUNC_PASS_ONLOCAL = FUNC_PASS_ONLOCAL.toInteger() + passCount.toInteger()
                                FUNC_ABORT_ONLOCAL = FUNC_ABORT_ONLOCAL.toInteger() + abortCount.toInteger()
                                FUNC_FAIL_ONLOCAL = FUNC_FAIL_ONLOCAL.toInteger() + failCount.toInteger()
                                FUNC_SKIP_ONLOCAL = FUNC_SKIP_ONLOCAL.toInteger() + skippedCount.toInteger()
                            }
                        }
                    }
                }
                parallel stepsForParallel
                }
            }
          }
        }

      }
    }

    stage('publish_results') {
      when {
        beforeAgent true
        expression { params.ENABLED_STAGES.contains('publish_results') }
      }
      agent {
        node {
          label 'meta_slave'
        }
      }
      steps {
        reportStageStatus("FuncTestsFailedOnLocal", "${FUNC_FAIL_ONLOCAL}")
        reportStageStatus("FuncTestsFailedOnAzure", "${FUNC_FAIL_ONAZURE}")
        reportStageStatus("FuncTestsPassOnLocal", "${FUNC_PASS_ONLOCAL}")
        reportStageStatus("FuncTestsPassOnAzure", "${FUNC_PASS_ONAZURE}")
        reportStageStatus("FuncTestsAbortOnLocal", "${FUNC_ABORT_ONLOCAL}")
        reportStageStatus("FuncTestsAbortOnAzure", "${FUNC_ABORT_ONAZURE}")
        reportStageStatus("FuncTestsSkippedOnAzure", "${FUNC_SKIP_ONAZURE}")
        reportStageStatus("FuncTestsSkippedOnLocal", "${FUNC_SKIP_ONLOCAL}")
      }
    }

    stage('send_mail') {
      when {
        beforeAgent true
        expression { params.ENABLED_STAGES.contains('send_mail') }
      }
      agent {
        node {
          label 'meta_slave'
        }
      }
      steps {
          sh '''#!/bin/bash
              KERNEL_SOURCE="${KERNEL_GIT_URL##*/}"
              KERNEL_SOURCE="${KERNEL_SOURCE%.*}"
              KERNEL_SOURCE=$(echo $KERNEL_SOURCE | tr /a-z/ /A-Z/)
              echo ${KERNEL_SOURCE} > ./kernel_source
          '''
          script {
              KERNEL_SOURCE = readFile "./kernel_source"
          }
          withCredentials([string(credentialsId: 'MAIL_LIST', variable: 'MAIL_LIST')]) {
            emailext (
            subject: "Test results for ${KERNEL_SOURCE} against ${DISTRO_VERSION}",
            to: "${env.MAIL_LIST}",
            mimeType : "text/html",
            body: '${SCRIPT, template="ubuntu.template"}'
            )
          }
      }
    }

  }
}
