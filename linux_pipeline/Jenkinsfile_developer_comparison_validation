#!/usr/bin/env groovy

env.SLAVE_PIPELINE_NAME = "Developers/pipeline-developer-patch-runner"
env.SEND_EMAIL = true
env.BUILD_KERNEL_ARTIFACTS = true
env.KERNEL_ARTIFACTS_SMB_PATH = ""
env.PARAM_SEPARATOR_STYLE = 'font-size: 15px; font-weight: 600;'

properties ([
    overrideIndexTriggers(false),
    [$class: 'ParametersDefinitionProperty',
        parameterDefinitions: [
        [$class: 'ParameterSeparatorDefinition',
            separatorStyle: "",
            sectionHeader: "KERNEL BUILD CONFIGURATION",
            sectionHeaderStyle: env.PARAM_SEPARATOR_STYLE],
        [$class: 'ChoiceParameterDefinition',
            name: 'KERNEL_GIT_URL',
            choices: """git://git.kernel.org/pub/scm/linux/kernel/git/next/linux-next.git\nhttps://git.kernel.org/pub/scm/linux/kernel/git/davem/net-next.git\nazure_kernel""",
            description: 'Kernel tree repo'],
        [$class: 'StringParameterDefinition',
            name: 'KERNEL_GIT_BRANCH',
            defaultValue: 'master',
            description: 'Branch to be built'],
        [$class: 'StringParameterDefinition',
            name: 'KERNEL_PATCH',
            defaultValue: "",
            description: 'Valid examples: \n scp://my-scp-hostname:/home/my-username/patch.p1 \n scp://my-username@my-scp-hostname:/home/my-username/patch.p1 \n http://my-website.com/patch.p1 \n Use the space separator for multiple patches.'],
        [$class: 'BooleanParameterDefinition',
            defaultValue: false,
            name: 'SKIP_UNPATCHED',
            description: 'Whether to skip unpatched run. No result comparison will be possible.'],
        [$class: 'ParameterSeparatorDefinition',
            separatorStyle: "",
            sectionHeader: "TEST CONFIGURATION",
            sectionHeaderStyle: env.PARAM_SEPARATOR_STYLE],
        [$class: 'ChoiceParameterDefinition',
            choices: """westus2\naustraliaeast\naustraliasoutheast\nbrazilsouth\ncanadacentral
                        canadaeast\ncentralindia\ncentralus\neastasia\neastus\neastus2\nfrancecentral
                        japaneast\njapanwest\nkoreacentral\nkoreasouth\nnorthcentralus\nnortheurope
                        southcentralus\nsoutheastasia\nsouthindia\nuksouth\nukwest\nwestcentralus
                        westeurope\nwestindia\nwestus\nsepremium""",
            name: 'LISAV2_AZURE_REGION',
            description: 'Azure Region'],
        [$class: 'StringParameterDefinition',
            name: 'LISAV2_VM_SIZE',
            defaultValue: "",
            description: 'LISAv2 VM size. If set, all the boot/functional/performance tests will use that VM size. If not set, the default test case VM size will be used. Make sure that the vm size exists and that the region supports it. '],
        [$class: 'ParameterSeparatorDefinition',
            separatorStyle: "",
            sectionHeader: "AZURE BOOT TEST CONFIGURATION",
            sectionHeaderStyle: env.PARAM_SEPARATOR_STYLE],
        [$class: 'BooleanParameterDefinition',
            defaultValue: true,
            name: 'RUN_AZURE_BOOT_TEST',
            description: 'Whether to run Azure Boot test'],
        [$class: 'ParameterSeparatorDefinition',
            separatorStyle: "",
            sectionHeader: "AZURE BOOT STRESS TEST CONFIGURATION",
            sectionHeaderStyle: env.PARAM_SEPARATOR_STYLE],
        [$class: 'BooleanParameterDefinition',
            defaultValue: false,
            name: 'RUN_AZURE_BOOT_STRESS_TEST',
            description: 'Whether to run Azure Boot Stress test.'],
        [$class: 'StringParameterDefinition',
            name: 'AZURE_BOOT_STRESS_PROVISIONING_NUMBER',
            defaultValue: "3",
            description: 'Azure VM provisioning number (how many times to recreate the VM).'],
        [$class: 'StringParameterDefinition',
            name: 'AZURE_BOOT_STRESS_REBOOT_NUMBER',
            defaultValue: "10",
            description: 'Azure VM reboot number for each provisioning iteration. The total reboot number will be: AZURE_BOOT_STRESS_PROVISIONING_NUMBER * AZURE_BOOT_STRESS_REBOOT_NUMBER.'],
        [$class: 'ParameterSeparatorDefinition',
            separatorStyle: "",
            sectionHeader: "FUNCTIONAL TEST CONFIGURATION",
            sectionHeaderStyle: env.PARAM_SEPARATOR_STYLE],
        [$class: 'ChoiceParameterDefinition',
            choices: """NONE
                    Azure
                    HyperV""",
            name: 'FUNCTIONAL_TESTS_PLATFORM',
            description: 'On which platform to run LISAv2 functional tests.'],
        [$class: 'StringParameterDefinition',
            name: 'FUNCTIONAL_TESTS_CATEGORY',
            defaultValue: "BVT",
            description: 'LISAv2 test case category. Available options can be retrieved using LISAv2\\Utilities\\Get-LISAv2Statistics.ps1. If left empty, all the test categories will be run.'],
        [$class: 'StringParameterDefinition',
            name: 'FUNCTIONAL_TESTS_AREA',
            defaultValue: "",
            description: 'LISAv2 test case area. Available options can be retrieved using LISAv2\\Utilities\\Get-LISAv2Statistics.ps1. If left empty, all the test areas will be run.'],
        [$class: 'StringParameterDefinition',
            name: 'FUNCTIONAL_TESTS_TAG',
            defaultValue: "",
            description: 'LISAv2 test case tag. Available options can be retrieved using LISAv2\\Utilities\\Get-LISAv2Statistics.ps1. If left empty, all the test tags will be run.'],
        [$class: 'StringParameterDefinition',
            name: 'FUNCTIONAL_TESTS_NAME',
            defaultValue: "",
            description: 'LISAv2 test case name. Available options can be retrieved using LISAv2\\Utilities\\Get-LISAv2Statistics.ps1. If left empty, all the tests will be run.'],
        [$class: 'ParameterSeparatorDefinition',
            separatorStyle: "",
            sectionHeader: "AZURE PERFOMANCE TEST CONFIGURATION",
            sectionHeaderStyle: env.PARAM_SEPARATOR_STYLE],
        [$class: 'ChoiceParameterDefinition',
            choices: """NONE
                    STORAGE
                    NETWORK""",
            name: 'AZURE_PERF_TESTS',
            description: 'What Azure Performance tests to run. You can customize the test cases from the options below.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """4k
                    1024k""",
            name: 'AZURE_PERF_STORAGE_IO_SIZE',
            description: 'Azure Performance STORAGE IO SIZE.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """ALL
                    randread
                    randwrite
                    read
                    write""",
            name: 'AZURE_PERF_STORAGE_IO_MODE',
            description: 'Azure Performance STORAGE IO MODE.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """IPERF3_1CONNECTION
                    NTTTCP_TCP
                    NTTTCP_UDP""",
            name: 'AZURE_PERF_NETWORK_TEST_TYPE',
            description: 'Azure Performance Network testing type.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """SYNTHETIC
                    SRIOV""",
            name: 'NET_IPERF3_TYPE',
            description: 'Azure Performance NETWORK IPERF3 1CONNECTION: SYNTHETIC or SRIOV type.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """ALL
                    32\n64\n128\n256\n512\n1024\n2048\n4096\n8192\n16384\n32768\n65536""",
            name: 'NET_IPERF3_BUFFER_LENGTH',
            description: 'Azure Performance NETWORK IPERF3 1CONNECTION BUFFER LENGTH.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """SYNTHETIC
                    SRIOV""",
            name: 'NTTTCP_TCP_TYPE',
            description: 'Azure Performance NETWORK NTTTCP TCP: SYNTHETIC or SRIOV type.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """ALL
                    1\n2\n4\n8\n16\n32\n64\n128\n256\n512\n1024\n2048\n4096\n6144\n8192\n10240""",
            name: 'NTTTCP_TCP_CONNECTIONS',
            description: 'Azure Performance NETWORK NTTTCP TCP number of connections.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """SYNTHETIC
                    SRIOV""",
            name: 'NTTTCP_UDP_TYPE',
            description: 'Azure Performance NETWORK NTTTCP UDP: SYNTHETIC or SRIOV type.'],
        [$class: 'ChoiceParameterDefinition',
            choices: """ALL
                    2\n4\n8\n16\n32\n64\n128\n256\n512\n1024""",
            name: 'NTTTCP_UDP_CONNECTIONS',
            description: 'Azure Performance NETWORK NTTTCP UDP number of connections.']
        ]
    ]
])


// ****************
// PIPELINE HELPERS
// ****************

def getCommonParams(patches, buildTag) {
    return [
        string(name: 'KERNEL_GIT_URL', value: params.KERNEL_GIT_URL),
        string(name: 'KERNEL_GIT_BRANCH', value: params.KERNEL_GIT_BRANCH),
        string(name: 'KERNEL_ARTIFACTS_SMB_PATH', value: env.KERNEL_ARTIFACTS_SMB_PATH),
        string(name: 'KERNEL_PATCH', value: patches),
        booleanParam(name: 'BUILD_KERNEL_ARTIFACTS', value: env.BUILD_KERNEL_ARTIFACTS.toBoolean()),
        string(name: 'LISAV2_AZURE_REGION', value: params.LISAV2_AZURE_REGION),
        booleanParam(name: 'RUN_AZURE_BOOT_TEST', value: params.RUN_AZURE_BOOT_TEST),
        booleanParam(name: 'RUN_AZURE_BOOT_STRESS_TEST', value: params.RUN_AZURE_BOOT_STRESS_TEST),
        string(name: 'LISAV2_VM_SIZE', value: params.LISAV2_VM_SIZE),
        string(name: 'AZURE_BOOT_STRESS_PROVISIONING_NUMBER', value: params.AZURE_BOOT_STRESS_PROVISIONING_NUMBER),
        string(name: 'AZURE_BOOT_STRESS_REBOOT_NUMBER', value: params.AZURE_BOOT_STRESS_REBOOT_NUMBER),
        string(name: 'FUNCTIONAL_TESTS_PLATFORM', value: params.FUNCTIONAL_TESTS_PLATFORM),
        string(name: 'FUNCTIONAL_TESTS_AREA', value: params.FUNCTIONAL_TESTS_AREA),
        string(name: 'FUNCTIONAL_TESTS_CATEGORY', value: params.FUNCTIONAL_TESTS_CATEGORY),
        string(name: 'FUNCTIONAL_TESTS_TAG', value: params.FUNCTIONAL_TESTS_TAG),
        string(name: 'FUNCTIONAL_TESTS_NAME', value: params.FUNCTIONAL_TESTS_NAME),
        string(name: 'AZURE_PERF_TESTS', value: params.AZURE_PERF_TESTS.trim()),
        string(name: 'AZURE_PERF_STORAGE_IO_SIZE', value: params.AZURE_PERF_STORAGE_IO_SIZE.trim()),
        string(name: 'AZURE_PERF_STORAGE_IO_MODE', value: params.AZURE_PERF_STORAGE_IO_MODE.trim()),
        string(name: 'AZURE_PERF_NETWORK_TEST_TYPE', value: params.AZURE_PERF_NETWORK_TEST_TYPE.trim()),
        string(name: 'NET_IPERF3_TYPE', value: params.NET_IPERF3_TYPE.trim()),
        string(name: 'NET_IPERF3_BUFFER_LENGTH', value: params.NET_IPERF3_BUFFER_LENGTH.trim()),
        string(name: 'NTTTCP_TCP_TYPE', value: params.NTTTCP_TCP_TYPE.trim()),
        string(name: 'NTTTCP_TCP_CONNECTIONS', value: params.NTTTCP_TCP_CONNECTIONS.trim()),
        string(name: 'NTTTCP_UDP_TYPE', value: params.NTTTCP_UDP_TYPE.trim()),
        string(name: 'NTTTCP_UDP_CONNECTIONS', value: params.NTTTCP_UDP_CONNECTIONS.trim()),
        string(name: 'CUSTOM_BUILD_TAG', value: "${buildTag}-${BUILD_NUMBER}")
    ]
}


// *************
// PIPELINE MAIN
// *************


node ("meta_slave") {
    def runs = [:]
    def patchedRun, unpatchedRun;
    def patchedParams = getCommonParams(env.KERNEL_PATCH, "patched")

    stage ("test_kernels") {
        runs["kernel_patched"] = {
            patchedRun = build job: "${env.SLAVE_PIPELINE_NAME}/${env.BRANCH_NAME}",
                         parameters: patchedParams, propagate: false;
            env.patchedRunNumber = patchedRun.number
        }
        if (!params.SKIP_UNPATCHED) {
            def unpatchedParams = getCommonParams("", "unpatched")
            runs["kernel_unpatched"] = {
                unpatchedRun = build job: "${env.SLAVE_PIPELINE_NAME}/${env.BRANCH_NAME}",
                               parameters: unpatchedParams, propagate: false;
                env.unpatchedRunNumber = unpatchedRun.number
            }
        }
        parallel runs
    }
}

def compareResultsRetries = 0
def compareResultsMaxRetries = 3
def compareResultsSuccess = false
while (!compareResultsSuccess && compareResultsRetries < compareResultsMaxRetries) {
    try {
        node ("meta_slave") {
            stage ("compare_results") {
                checkout scm
                def mailErrorMessages = ""
                dir ('aggregate_results' + env.BUILD_NUMBER + env.BRANCH_NAME) {
                    echo "Aggregate results"
                    sh '''#!/bin/bash
                        set -xe
                        output_file="${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/aggregate-junit.xml"
                        echo "<testsuites>" > "${output_file}"
                    '''
                    try {
                        copyArtifacts(projectName: "${env.SLAVE_PIPELINE_NAME}/${env.BRANCH_NAME}",
                                      selector: specific("${env.patchedRunNumber}"),
                                      target: "patched_run");
                        sh '''
                            #!/bin/bash
                            set -xe
                            output_file="${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/aggregate-junit.xml"
                            cd "${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/patched_run/Report/"
                            for filename in AZURE_BOOT_TEST AZURE_BOOT_STRESS_TEST LISAV2_FUNCTIONAL_TESTS; do
                                if [ -f "${filename}.xml" ]; then
                                    sed -i "s/LISAv2Test/LISAv2Patched-${filename}/g" "${filename}.xml"
                                    grep -v '<testsuites>\\|</testsuites>' "${filename}.xml" >> "${output_file}"
                                fi
                            done
                        '''
                    } catch (Exception e) {
                        echo e.toString()
                        mailErrorMessages += "Failed to copy artifacts from patched downstream build ${env.patchedRunNumber}. </br>\n"
                    }
                    try {
                        if (!params.SKIP_UNPATCHED) {
                            copyArtifacts(projectName: "${env.SLAVE_PIPELINE_NAME}/${env.BRANCH_NAME}",
                                          selector: specific("${env.unpatchedRunNumber}"),
                                          target: "unpatched_run");
                            sh '''#!/bin/bash
                                set -xe
                                output_file="${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/aggregate-junit.xml"
                                cd "${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/unpatched_run/Report/"
                                for filename in AZURE_BOOT_TEST AZURE_BOOT_STRESS_TEST LISAV2_FUNCTIONAL_TESTS; do
                                    if [ -f "${filename}.xml" ]; then
                                        sed -i "s/LISAv2Test/LISAv2Unpatched-${filename}/g" "${filename}.xml"
                                        grep -v '<testsuites>\\|</testsuites>' "${filename}.xml" >> "${output_file}"
                                    fi
                                done
                            '''
                        }
                    } catch (Exception e) {
                        echo e.toString()
                        mailErrorMessages +=  "Failed to copy artifacts from unpatched downstream build ${env.unpatchedRunNumber}. </br>\n"
                    }
                    sh '''#!/bin/bash
                        set -xe
                        output_file="${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/aggregate-junit.xml"
                        echo "</testsuites>" >> "${output_file}"
                    '''
                    try {
                        junit "aggregate-junit.xml"
                    } catch (Exception e) {
                        echo e.toString()
                        mailErrorMessages += "Failed to find any jUnit test results. </br> \n"
                    }
                    archiveArtifacts 'aggregate-junit.xml'
                    sh '''#!/bin/bash
                        python3 "${WORKSPACE}/scripts/comparison/html_parser.py" \\
                            --patched_perf_dir "${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/patched_run/Report" \\
                            --unpatched_perf_dir "${WORKSPACE}/aggregate_results${BUILD_NUMBER}${BRANCH_NAME}/unpatched_run/Report/" \\
                            --junit_test_results ./aggregate-junit.xml --output ./results.html
                    '''
                    archiveArtifacts 'results.html'

                    if (env.SEND_EMAIL) {
                        mailBody = "Hello,</br></br>\n</br>\n"
                        mailBody = "<h5> Developer Patch Validation Pipeline <a href='${env.BUILD_URL}'>#${env.BUILD_NUMBER}</a> has completed.</h5></br>\n"
                        if (env.KERNEL_PATCH && env.KERNEL_PATCH != '') {
                            mailBody += "The following kernel patches were applied:</br>\n"
                            patches = env.KERNEL_PATCH.split(" ")
                            patches.each(){
                                mailBody += it + "</br>\n"
                            }
                        } else {
                            mailBody += "No kernel patches were applied." + "</br>\n"
                        }
                        mailBody += mailErrorMessages
                        mailBody += readFile("results.html")
                        emailext (
                            subject: "Developer patch validation report for run: #${env.BUILD_NUMBER}.",
                            recipientProviders: [[$class: 'RequesterRecipientProvider']],
                            mimeType : "text/html",
                            body: mailBody
                        )
                        deleteDir()
                    }
                }
            }
            compareResultsSuccess = true
        }
    } catch (Exception e) {
        compareResultsRetries++
        echo e.toString()
        echo "Retrying compare results stage."
    }
}
