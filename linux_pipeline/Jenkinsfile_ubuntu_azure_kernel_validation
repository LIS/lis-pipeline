#!/usr/bin/env groovy

def RunPowershellCommand(psCmd) {
    bat "powershell.exe -NonInteractive -ExecutionPolicy Bypass -Command \"[Console]::OutputEncoding=[System.Text.Encoding]::UTF8;$psCmd;EXIT \$global:LastExitCode\""
}

def GetTestResults(type) {
    withEnv(["Type=${type}"]) {
        def returnValues = powershell returnStdout: true, script: '''
            $file = Get-Item ".\\Report\\*-junit.xml" -ErrorAction SilentlyContinue | Sort-Object LastWriteTimeUtc | select -Last 1
            if (!$file) {
                return 0
            }
            $content = [xml](Get-Content $file)
            $failCase = [int]($content.testsuites.testsuite.failures)
            $allCase = [int]($content.testsuites.testsuite.tests)
            $abortCase = [int]($content.testsuites.testsuite.errors)
            $skippedCase = [int]($content.testsuites.testsuite.skipped)
            $passCase = $allCase - $failCase - $abortCase - $skippedCase

            if ($env:Type -eq "pass") {
                return $passCase
            } elseif ($env:Type -eq "abort") {
                return $abortCase
            } elseif ($env:Type -eq "fail") {
                return $failCase
            } elseif ($env:Type -eq "skipped") {
                return $skippedCase
            } elseif ($env:Type -eq "all") {
                return $allCase
            }
        '''
        return "${returnValues}"
    }
}

def reportPipelineStatus(status) {
    println "Pipeline report for status: ${status}"

    env.COMPOSITE_KEYS = "PipelineName,PipelineBuildNumber"
    withCredentials(bindings: [file(credentialsId: 'KERNEL_PIPELINE_EXECUTION_DB_CREDS',
        variable: 'KERNEL_PIPELINE_EXECUTION_DB_CREDS')]) {
        dir('ker_pi_rep' + env.BUILD_NUMBER + env.BRANCH_NAME) {
            sh '''#!/bin/bash
                cat << EOF > "${WORKSPACE}/scripts/reporting/db_rows_${BRANCH_NAME}_${BUILD_NUMBER}.json"
[{  "StartDate": "${START_DATE}",
    "EndDate": "${END_DATE}",
    "PipelineName": "${JOB_NAME}",
    "PipelineBuildNumber": ${BUILD_NUMBER},
    "PipelineBuildUrl": "${BUILD_URL}",
    "KernelVersion": "${KernelVersion}",
    "KernelType": "${KERNEL_TYPE}",
    "SignedOffBy": "${SIGNED_OFF_BY}",
    "SignedOffResult": "${SIGNED_OFF_RESULT}",
    "DistroVersion": "${Distro}"  }]
EOF
                python "${WORKSPACE}/scripts/reporting/report_pipeline_stage_status.py" \
                --db_rows "${WORKSPACE}/scripts/reporting/db_rows_${BRANCH_NAME}_${BUILD_NUMBER}.json" \
                --composite_keys "${COMPOSITE_KEYS}" \
                --db_config "${KERNEL_PIPELINE_EXECUTION_DB_CREDS}"
            '''
        }
    }
}

def reportStageStatus(stageInfo, useTestResults) {
    env.stageName = stageInfo["Name"]
    env.currentPlatform = stageInfo["Platform"]
    env.startDate = stageInfo["StartDate"]
    env.endDate = stageInfo["EndDate"]

    env.passCount = ''
    env.abortCount = ''
    env.failCount = ''
    env.skippedCount = ''
    if (useTestResults) {
        env.passCount = GetTestResults("pass").trim()
        env.abortCount = GetTestResults("abort").trim()
        env.failCount = GetTestResults("fail").trim()
        env.skippedCount = GetTestResults("skipped").trim()
    }

    env.MASTER_COMPOSITE_KEYS = "PipelineName,PipelineBuildNumber"
    env.COMPOSITE_KEYS = "StageName"
    env.FOREIGN_KEY = "PipelineExecutionId"
    stage ("report_stage") {
        node ("meta_slave") {

            withCredentials(bindings: [file(credentialsId: 'KERNEL_PIPELINE_EXECUTION_STAGE_DB_CREDS',
                variable: 'KERNEL_PIPELINE_EXECUTION_STAGE_DB_CREDS')]) {
                checkout scm
                sh '''#!/bin/bash
        cat << EOF > "${WORKSPACE}/scripts/reporting/db_rows${stageName}${BUILD_NUMBER}${BRANCH_NAME}.json"
[{  "StageName": "${stageName}",
"StartDate": "${startDate}",
"EndDate": "${endDate}",
"TestsPassed": "${passCount}",
"TestsAborted": "${abortCount}",
"TestsFailed": "${failCount}",
"TestsSkipped": "${skippedCount}",
"PipelineName": "${JOB_NAME}",
"PipelineBuildNumber": ${BUILD_NUMBER},
"Platform": "${currentPlatform}"  }]
EOF
            python "${WORKSPACE}/scripts/reporting/report_pipeline_stage_status.py" \
                --db_rows "${WORKSPACE}/scripts/reporting/db_rows${stageName}${BUILD_NUMBER}${BRANCH_NAME}.json" \
                --composite_keys "${COMPOSITE_KEYS}" \
                --foreign_key "${FOREIGN_KEY}" \
                --master_composite_keys "${MASTER_COMPOSITE_KEYS}" \
                --db_config "${KERNEL_PIPELINE_EXECUTION_STAGE_DB_CREDS}"
            '''
            }
        }
    }
}

def sendSignOffMail(mailType,warningMessage) {
    def kernelAndDistroID = "${env.KernelType} ${env.KernelVersion} kernel for ${env.distro}"
    def SIGNOFF_EMAIL_SUBJECT_HASH = [
        'true' : "was reviewed by ${env.SIGNED_OFF_BY}",
        'false' : "was reviewed by ${env.SIGNED_OFF_BY}",
        'Superseded' : "was reviewed by ${env.SIGNED_OFF_BY}",
        'timeout' : "was not signed off in time"]
    def SIGNOFF_EMAIL_MESSAGE_HASH = [
        'true' : "is OK and was signed off by ${env.SIGNED_OFF_BY}",
        'false' : "is not ok / cannot be signed off. Reviewed by ${env.SIGNED_OFF_BY}",
        'Superseded' : "was superseded during testing. Reviewed by ${env.SIGNED_OFF_BY}",
        'timeout' : "was not signed off in time."]
    mailText = kernelAndDistroID + " " + SIGNOFF_EMAIL_MESSAGE_HASH[mailType]
    mailSubject = kernelAndDistroID + " " + SIGNOFF_EMAIL_SUBJECT_HASH[mailType]

    withCredentials([string(credentialsId: 'MAIL_LIST_SIGNOFF', variable: 'MAIL_LIST_SIGNOFF')]) {
        def emailList = ""
        if (env.sendMail == "yes") {
            emailList = env.MAIL_LIST_SIGNOFF
        }
        emailext (
            subject: "${mailSubject}",
            to: emailList,
            recipientProviders: [[$class: 'RequesterRecipientProvider']],
            mimeType : "text/html",
            body: """
                Hello,<br/><br/>
                ${mailText}.<br/>
                ${warningMessage}<br/>
                URL: ${env.BUILD_URL}<br/><br/>
                Thank you,<br/>Jenkins CI
            """
        )
    }
}

properties ([
    overrideIndexTriggers(false),
    parameters([
        choice (name: 'Distro', choices: 'trusty\nxenial\nbionic\neoan\nfocal',
                description: 'trusty - 14.04 validation <br> xenial - 16.04 validation <br> bionic - 18.04 validation <br> eoan - 19.10 validation <br> focal - 20.04 validation'),
        choice (name: 'KernelType', choices: 'linux-azure\nlinux-azure-edge',
                description: 'linux-azure - latest proposed linux-azure kernel validation <br> linux-azure-edge - latest proposed linux-azure-edge kernel validation'),
        string(name: 'KernelVersion', defaultValue: "", description: 'The exact kernel version to be tested. Example: 5.0.0.1010.9. If left empty, the latest kernel version for the selected distro/kernel type will be used.'),
        choice (name: 'ValidationAzure', choices: 'yes\nno',
                description: 'yes - will do Azure validation testing <br> no - Azure validation testing will be skipped'),
        choice (name: 'ValidationHyperV', choices: 'yes\nno',
                description: 'yes - will do HyperV validation testing <br> no - HyperV validation testing will be skipped'),
        choice (name: 'PerformanceAzure', choices: 'yes\nno',
                description: 'yes - will do Azure Performance testing <br> no - Azure Performance testing will be skipped'),
        choice (name: 'sendMail', choices: 'no\nyes',
                description: 'no - will send email notification only to the person who started the pipeline run. <br> yes - will send email notification to all the pipeline owners.')
    ])
])

def ARM_DISTRO_HASH = [trusty:'Canonical UbuntuServer 14.04.5-LTS latest',
                  xenial:'Canonical UbuntuServer 16.04-LTS latest',
                  bionic:'Canonical UbuntuServer 18.04-LTS latest',
                  eoan:'Canonical UbuntuServer 19.10-DAILY latest',
                  focal:'canonical 0001-com-ubuntu-server-focal-daily 20_04-daily-lts latest']
def HYPERV_VHD_HASH = [trusty:'Ubuntu_14.04.5\\Ubuntu14.04.5-server.vhdx',
                  xenial:'ubuntu_16.04.5\\ubuntu_16.04.5.vhdx',
                  bionic:'ubuntu_18.04.1\\ubuntu_18.04.1_gen1_gen2.vhdx',
                  eoan: 'ubuntu_19.10\\ubuntu_19.10.vhdx',
                  focal: 'ubuntu_20.04\\ubuntu_20.04.vhdx']

def HYPERV_VALIDATION_TESTS_HASH = [HV_P0_VALIDATION:"-TestPriority 0 -ExcludeTests '^NVME,^SRIOV-*,^LIVE-MIGRATE*,ETHTOOL-OFFLOADING-SETTING,ETHTOOL-OFFLOADING-SETTING-3NICS,^LIS-DEPLOY*'",
    HV_P1_VALIDATION:"-TestPriority 1 -ExcludeTests '^PERF-*,^NVME-*,^SRIOV-*,^LIVE-MIGRATE*,DYNAMIC-MEMORY-HIGH-PRIORITY,^LIS-PREINSTALL*'",
    HV_SRIOV_VALIDATION:"-TestCategory 'Functional' -TestArea 'SRIOV' -ExcludeTests 'SRIOV-MOVE-VHD'"]

def AZURE_VALIDATION_TESTS_HASH = [AZURE_P0_VALIDATION:"-TestPriority 0 -ExcludeTests '^NVME-*,VERIFY-DPDK-COMPLIANCE,^LIS-DEPLOY*,^LIS-DRIVER*'",
    AZURE_P1_VALIDATION:"-TestPriority 1 -ExcludeTests '^NVME-*,^PERF-*,INFINIBAND-HPCX-MPI-2VM,^LIS-PREINSTALL*'",
    AZURE_P2_VALIDATION:"-TestPriority 2 -ExcludeTests '^NVME-*,^PERF-*,TENSORFLOW*,NESTED*,VERIFY-DPDK-NFF-GO,VERIFY-DPDK-OVS,STRESSTEST-NVME-4K-IO'",
    AZURE_NVME_VALIDATION:"-TestCategory 'Functional' -TestArea 'NVME'",
    AZURE_SGX_VALIDATION:"-TestNames VALIDATE-INTEL-SGX-DRIVER-FOR-DC-VM"]

def AZURE_PERFORMANCE_TESTS_HASH = [PERF_NTTTCP:"-TestNames 'PERF-NETWORK-TCP-THROUGHPUT-MULTICONNECTION-NTTTCP-Synthetic,PERF-NETWORK-TCP-THROUGHPUT-MULTICONNECTION-NTTTCP-SRIOV' -ResultDBTable 'Perf_Network_TCP_Azure_DefaultKernel'",
    PERF_UDP:"-TestNames 'PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICONNECTION-NTTTCP-Synthetic,PERF-NETWORK-UDP-1K-THROUGHPUT-MULTICONNECTION-NTTTCP-SRIOV' -ResultDBTable 'Perf_Network_UDP_Azure_DefaultKernel'",
    PERF_SINGLE_IPERF:"-TestNames 'PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SYNTHETIC,PERF-NETWORK-TCP-SINGLE-CONNECTION-THROUGHPUT-SRIOV' -ResultDBTable 'Perf_Network_Single_TCP_Azure_DefaultKernel'",
    PERF_LATENCY:"-TestNames 'PERF-NETWORK-TCP-LATENCY-Synthetic,PERF-NETWORK-TCP-LATENCY-SRIOV' -ResultDBTable 'Perf_Network_Latency_Azure_DefaultKernel'",
    PERF_STORAGE_4K:"-TestNames 'PERF-STORAGE-4K-IO' -StorageAccount 'ExistingStorage_Premium' -ResultDBTable 'Perf_Storage_Azure_DefaultKernel'",
    NESTED_NTTTCP_PRIVATE_BRIDGE: "-TestNames 'NESTED-KVM-NTTTCP-PRIVATE-BRIDGE' -CustomTestParameters 'NESTED_NTTTCP_TCP_CONNECTIONS=(32 64 128)'",
    NESTED_NTTTCP_DIFFERENT_L1_NAT: "-TestNames 'AZURE-NESTED-KVM-NTTTCP-DIFFERENT-L1-NAT' -CustomTestParameters 'NESTED_NTTTCP_TCP_CONNECTIONS=(8 16 32)'"]
LATEST_VERSION_LOCATION="/home/lisa/latest_versions.sh"
LABEL_SRIOV = "sriov_mlnx"
LABEL_WS2016 = "ubuntu_azure_kernel_validation"
LISAV2_REMOTE = "https://github.com/lis/LISAv2.git"
LISAV2_BRANCH = "master"
AZURE_LOCATION_DEFAULT = "westus2"
AZURE_LOCATION_NVME = "eastus2"
AZURE_LOCATION_SGX = "uksouth"
AZURE_ID = "ubuntuAz"

def ARM_DISTRO = ARM_DISTRO_HASH.find{it.key == env.distro}.value
def HYPERV_VHD = HYPERV_VHD_HASH.find{it.key == env.distro}.value

if (env.KernelType == "linux-azure") {
    env.KERNEL_TYPE = "proposed-azure"
}
if (env.KernelType == "linux-azure-edge"){
    env.KERNEL_TYPE = "proposed-edge"
}

env.START_DATE = new java.sql.Timestamp(new Date().getTime())
env.END_DATE = ""
env.SIGNED_OFF_BY = ""
env.SIGNED_OFF_RESULT = ""

stage ("report_status_init") {
    node ("meta_slave") {
        checkout scm
        try {
            reportPipelineStatus("start")
        } catch (exc) {
            println exc
        }
    }
}

if (env.ValidationAzure == 'yes') {
    stage ("Azure-Validation-${env.distro}-${env.KernelType}") {
        def runs = [:]
        AZURE_VALIDATION_TESTS_HASH.each() {
            def test_type = it.key
            def test_cmd = it.value
            runs["${test_type}"] = {
                stage ("${test_type}") {
                    def AZURE_LOCATION = ""
                    if (test_cmd.contains("-TestArea 'NVME'")){
                        AZURE_LOCATION = AZURE_LOCATION_NVME
                    } else if (test_type.contains("AZURE_SGX_VALIDATION")) {
                        AZURE_LOCATION = AZURE_LOCATION_SGX
                    } else {
                        AZURE_LOCATION = AZURE_LOCATION_DEFAULT
                    }
                    node ("azure") {
                        try {
                            timeout (time: 48, unit: 'HOURS')  {
                                withCredentials(bindings: [
                                file(credentialsId:'Azure_Secrets_TESTONLY_File', variable: 'Azure_Secrets_File')]) {
                                    dir ("${distro}-${env.BUILD_NUMBER}-${env.BRANCH_NAME}") {
                                        cleanWs()
                                        git branch: LISAV2_BRANCH, url: LISAV2_REMOTE

                                        def stageInfo = [:]
                                        stageInfo["Name"] = "Azure-Validation-${env.distro}-${env.KernelType}-${test_type}"
                                        stageInfo["StartDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        stageInfo["EndDate"] = ''
                                        stageInfo["Platform"] = "Azure"
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, false)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }
                                        def ARM_GEN2_DISTRO = ""
                                        script {
                                            custom_test_cmd = ""
                                            if ("${env.distro}" == "bionic") {
                                                ARM_GEN2_DISTRO = "Canonical UbuntuServer 18_04-lts-gen2 latest"
                                                custom_test_cmd = "CustomTestParameters 'DPDK_SOURCE_URL=https://github.com/DPDK/dpdk.git'"
                                            }
                                            if ("${env.distro}" == "xenial") {
                                                ARM_GEN2_DISTRO = "Canonical UbuntuServer 16_04-lts-gen2 latest"
                                            }
                                            if ("${env.distro}" == "eoan") {
                                                ARM_GEN2_DISTRO = "Canonical UbuntuServer 19_10-daily-gen2 latest"
                                                custom_test_cmd = "CustomTestParameters 'DPDK_SOURCE_URL=https://github.com/DPDK/dpdk.git'"
                                            }
                                            if ("${env.distro}" == "focal") {
                                                ARM_GEN2_DISTRO = "canonical 0001-com-ubuntu-server-focal-daily 20_04-daily-lts-gen2 latest"
                                                custom_test_cmd = "CustomTestParameters 'DPDK_SOURCE_URL=https://github.com/DPDK/dpdk.git'"
                                            }
                                        }
                                        if (test_type == "AZURE_SGX_VALIDATION") {
                                            echo "Run-LisaV2.ps1 -TestPlatform 'Azure' -ARMImageName '${ARM_GEN2_DISTRO}' -RGIdentifier '${AZURE_ID}' -TestLocation '${AZURE_LOCATION}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${Azure_Secrets_File}'"
                                            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                                " -TestLocation '${AZURE_LOCATION}'" +
                                                " -RGIdentifier '${AZURE_ID}'" +
                                                " -TestPlatform 'Azure'" +
                                                " -CustomKernel '${KERNEL_TYPE}'" +
                                                " -ARMImageName '${ARM_GEN2_DISTRO}'" +
                                                " -XMLSecretFile '${Azure_Secrets_File}'" +
                                                " -EnableTelemetry" +
                                                " -ExitWithZero" +
                                                " ${test_cmd} ${custom_test_cmd}"
                                            )
                                        } else {
                                            echo "Run-LisaV2.ps1 -TestPlatform 'Azure' -ARMImageName '${ARM_DISTRO}' -RGIdentifier '${AZURE_ID}' -TestLocation '${AZURE_LOCATION}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${Azure_Secrets_File}'"
                                            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                                " -TestLocation '${AZURE_LOCATION}'" +
                                                " -RGIdentifier '${AZURE_ID}'" +
                                                " -TestPlatform 'Azure'" +
                                                " -CustomKernel '${KERNEL_TYPE}'" +
                                                " -ARMImageName '${ARM_DISTRO}'" +
                                                " -XMLSecretFile '${Azure_Secrets_File}'" +
                                                " -EnableTelemetry" +
                                                " -ExitWithZero" +
                                                " ${test_cmd}"
                                            )
                                        }
                                        archiveArtifacts artifacts: '*-TestLogs.zip', allowEmptyArchive: true
                                        junit testResults: "Report\\*-junit.xml", allowEmptyResults: true

                                        stageInfo["EndDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, true)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }
                                        deleteDir()
                                    }
                                }
                            }
                        } catch (exc) {
                            println exc
                            println "Azure-Validation-${test_type}: STAGE_FAILED_EXCEPTION."
                            currentBuild.result = 'SUCCESS'
                        }
                    }
                }
            }
        }
        parallel runs
    }
} else {
    echo "Skipping Azure validation"
}

if (env.ValidationHyperV == 'yes') {
    stage ("HyperV-Validation-${env.distro}-${env.KernelType}") {
        def runs = [:]
        HYPERV_VALIDATION_TESTS_HASH.each() {
            def test_type = it.key
            def test_cmd = it.value
            runs["${test_type}"] = {
                stage ("${test_type}") {
                    if (test_type == "HV_SRIOV_VALIDATION" && test_cmd.contains("TestArea 'SRIOV'")){
                        LABEL_NAME = LABEL_SRIOV
                    } else {
                        LABEL_NAME = LABEL_WS2016
                    }
                    node ("${LABEL_NAME}") {
                        try {
                            timeout (time: 24, unit: 'HOURS') {
                                withCredentials(bindings: [
                                string(credentialsId:'SRIOV_TEST_LOCATION', variable: 'SRIOV_TEST_LOCATION'),
                                string(credentialsId:'LISAV2_IMAGES_SHARE_URL', variable: 'LISAV2_IMAGES_SHARE_URL'),
                                file(credentialsId:'HYPERV_LISAV2_SECRETS', variable: 'HYPERV_LISAV2_SECRETS')]) {
                                    dir ("${test_type}-${env.BUILD_NUMBER}-${env.BRANCH_NAME}") {
                                        def stageInfo = [:]
                                        stageInfo["Name"] = "HyperV-Validation-${env.distro}-${env.KernelType}-${test_type}"
                                        stageInfo["StartDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        stageInfo["EndDate"] = ''
                                        stageInfo["Platform"] = "HyperV"
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, false)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }

                                        cleanWs()
                                        git branch: LISAV2_BRANCH, url: LISAV2_REMOTE
                                        if (test_type == "HV_SRIOV_VALIDATION") {
                                            test_location_sriov = "${SRIOV_TEST_LOCATION}"
                                            println "${test_type} - ${test_cmd} - ${test_location_sriov}"
                                            HYPERV_VHD_PATH = "${LISAV2_IMAGES_SHARE_URL}${HYPERV_VHD}"
                                            echo "Run-LisaV2.ps1 -TestPlatform 'HyperV' -OsVHD ${HYPERV_VHD_PATH} -RgIdentifier 'ubuntuAzure${distro}' -TestLocation '${test_location_sriov}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${HYPERV_LISAV2_SECRETS}'"
                                            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                                " -TestLocation '${test_location_sriov}'" +
                                                " -RGIdentifier 'ubuntuHV${distro}'" +
                                                " -TestPlatform 'HyperV'" +
                                                " -CustomKernel '${KERNEL_TYPE}'" +
                                                " -OsVHD '${HYPERV_VHD_PATH}'" +
                                                " -XMLSecretFile '${HYPERV_LISAV2_SECRETS}'" +
                                                " -EnableTelemetry" +
                                                " -ExitWithZero" +
                                                " ${test_cmd}"
                                            )
                                        } else {
                                            test_location = "localhost"
                                            println "${test_type} - ${test_cmd} - ${test_location}"
                                            HYPERV_VHD_PATH = "${LISAV2_IMAGES_SHARE_URL}${HYPERV_VHD}"
                                            echo "Run-LisaV2.ps1 -TestPlatform 'HyperV' -OsVHD ${HYPERV_VHD_PATH} -RgIdentifier 'ubuntuAzure${distro}' -TestLocation '${test_location}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${HYPERV_LISAV2_SECRETS}'"
                                            RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                                " -TestLocation '${test_location}'" +
                                                " -RGIdentifier 'ubuntuHV${distro}'" +
                                                " -TestPlatform 'HyperV'" +
                                                " -CustomKernel '${KERNEL_TYPE}'" +
                                                " -OsVHD '${HYPERV_VHD_PATH}'" +
                                                " -XMLSecretFile '${HYPERV_LISAV2_SECRETS}'" +
                                                " -EnableTelemetry" +
                                                " -ExitWithZero" +
                                                " ${test_cmd}"
                                            )
                                        }

                                        archiveArtifacts artifacts: '*-TestLogs.zip', allowEmptyArchive: true
                                        junit testResults: "Report\\*-junit.xml", allowEmptyResults: true

                                        stageInfo["EndDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, true)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }
                                        deleteDir()
                                    }
                                }
                            }
                        } catch (exc) {
                            println exc
                            println "HyperV-Validation-${test_type}: STAGE_FAILED_EXCEPTION."
                            currentBuild.result = 'SUCCESS'
                        }
                    }
                }
            }
        }
        parallel runs
    }
} else {
    echo "Skipping Hyper-V validation"
}

if (env.PerformanceAzure == "yes") {
    stage ("Performance-${env.distro}-${env.KernelType}") {
        def runs = [:]
        AZURE_PERFORMANCE_TESTS_HASH.each() {
            def test_type = it.key
            def test_cmd = it.value
            runs["${test_type}"] = {
                stage ("${test_type}") {
                    node ("azure"){
                        try {
                            timeout (time: 12, unit: 'HOURS')  {
                                withCredentials(bindings: [
                                file(credentialsId:'Azure_Secrets_TESTONLY_File', variable: 'Azure_Secrets_File')]) {
                                    dir ("${distro}-${env.BUILD_NUMBER}-${env.BRANCH_NAME}") {
                                        cleanWs()
                                        git branch: LISAV2_BRANCH, url: LISAV2_REMOTE

                                        def stageInfo = [:]
                                        stageInfo["Name"] = "Performance-Validation-${env.distro}-${env.KernelType}-${test_type}"
                                        stageInfo["StartDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        stageInfo["EndDate"] = ''
                                        stageInfo["Platform"] = "Azure"
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, false)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }

                                        echo "Run-LisaV2.ps1 -TestPlatform 'Azure' -ARMImageName '${ARM_DISTRO}' -RGIdentifier '${AZURE_ID}' -TestLocation '${AZURE_LOCATION_DEFAULT}' -CustomKernel '${KERNEL_TYPE}' ${test_cmd} -XMLSecretFile '${Azure_Secrets_File}'"
                                        RunPowershellCommand(".\\Run-LisaV2.ps1" +
                                            " -TestLocation '${AZURE_LOCATION_DEFAULT}'" +
                                            " -RGIdentifier '${AZURE_ID}'" +
                                            " -TestPlatform 'Azure'" +
                                            " -CustomKernel '${KERNEL_TYPE}'" +
                                            " -ARMImageName '${ARM_DISTRO}'" +
                                            " -XMLSecretFile '${Azure_Secrets_File}'" +
                                            " -EnableTelemetry" +
                                            " -ExitWithZero" +
                                            " -ResultDBTestTag '${env.distro}_${env.KernelType}_${env.BUILD_NUMBER}'" +
                                            " ${test_cmd}"
                                        )
                                        archiveArtifacts artifacts: '*-TestLogs.zip', allowEmptyArchive: true
                                        junit testResults: "Report\\*-junit.xml", allowEmptyResults: true

                                        stageInfo["EndDate"] = new java.sql.Timestamp(new Date().getTime()).toString()
                                        try {
                                            lock ('db_reporting') {
                                                reportStageStatus(stageInfo, true)
                                            }
                                        } catch (exc) {
                                            println exc
                                        }
                                        deleteDir()
                                    }
                                }
                            }
                        } catch (exc) {
                            println exc
                            println "Azure-${test_type}: STAGE_FAILED_EXCEPTION."
                            currentBuild.result = 'SUCCESS'
                        }
                    }
                }
            }
        }
        parallel runs
    }
} else {
    echo "Skipping Azure Performance"
}


node ("meta_slave") {
    echo "Send email with kernel validation results link"
    if (env.KernelType == "linux-azure") {
        version_identifier = "_azure"
    } else {
        version_identifier = "_edge"
    }
    def kernels_info = ""
    try {
        kernels_info = readFile (LATEST_VERSION_LOCATION)
    } catch (exc) {
        echo "${LATEST_VERSION_LOCATION} could not be found on the server!"
        return
    }
    kernels_info = kernels_info.split("\n")
    def latest_kernel_version = ""
    kernels_info.each {
        if (it.contains("${env.distro}${version_identifier}")) {
            latest_kernel_version = it.split("=")[1]
        }
    }

    def warningMessage = ""

    if (!env.KernelVersion) {
        env.KernelVersion = latest_kernel_version
    }

    if (env.KernelVersion && latest_kernel_version && env.KernelVersion.trim() != latest_kernel_version.trim()) {
        warningMessage = "Warning: kernel ${env.KernelVersion} superseded by ${latest_kernel_version}!"
    }
    stage('Send-email') {
        withCredentials([string(credentialsId: 'MAIL_LIST_OWNER', variable: 'MAIL_LIST_OWNER')]) {
            def emailList = ""
            if (env.sendMail == "yes") {
                emailList = env.MAIL_LIST_OWNER
            }
            emailext (
                subject: "Please sign off ${env.KernelType} ${env.KernelVersion} kernel for ${env.distro}. ${warningMessage}",
                to: emailList,
                mimeType : "text/html",
                body: '${SCRIPT, template="ubuntu.template"}',
                recipientProviders: [[$class: 'RequesterRecipientProvider']],
            )
        }
    }
    stage('Kernel-Sign-Off') {
        try {
            timeout(time: 72, unit: 'HOURS') {
                reviewer = input(message: "Start review for ${env.distro} ${env.KernelType} ${env.KernelVersion} kernel?\n${warningMessage}", submitterParameter: "USER")
                env.SIGNED_OFF_BY = reviewer.toString()
                env.SIGNED_OFF_RESULT = "UnderReview"
            }
            reportPipelineStatus("kernel-review")
        } catch (exc) {
            println exc
        }
        def owner
        try {
            checkout scm
            echo "Ask for manual sign-off from the owner"
            timeout(time: 36, unit: 'HOURS') {
                signoff = input (
                    parameters: [choice (
                        name: 'SignOff',
                        choices: 'Yes\nNo\nSuperseded',
                        description: "Are you sure you want to sign off ${env.distro} ${env.KernelType} ${env.KernelVersion} kernel?\n${warningMessage}")],
                    submitterParameter: "USER")
                owner = signoff["USER"].toString()
                signoffStatus = signoff['SignOff']

                def DB_COMPATIBILITY_HASH = [ "Yes":"true", "No":"false"]
                if (DB_COMPATIBILITY_HASH.containsKey(signoffStatus)) {
                    signoffStatus = DB_COMPATIBILITY_HASH[signoffStatus]
                }
            }
            env.SIGNED_OFF_BY = owner
            env.SIGNED_OFF_RESULT = signoffStatus
            sendSignOffMail(signoffStatus,warningMessage)
        } catch (exc) {
            env.SIGNED_OFF_RESULT = "false"
            sendSignOffMail('timeout',warningMessage)
        }
    }
}


stage ("report_status_end") {
    node ("meta_slave") {
        checkout scm
        env.END_DATE = new java.sql.Timestamp(new Date().getTime())
        try {
            reportPipelineStatus("finish")
        } catch (exc) {
            println exc
        }
    }
}
